Intro to Descriptive Statistics
===============================

Lesson 1: Intro to Research Methods
-----------------------------------
Descriptive Statistics allows to summarize data and shape how to make decisions.

It involves gathering, organizing, computing, and visualizing information from 
	the dataset.

A good sample size, a representative sample, and a sound methodology are important
	to conduct a valid research.

Describe your problem statement explicitly (Define Constructs).

A construct is an idea or theory containing various conceptual elements, typically 
	one considered to be subjective and not based on empirical evidence.

Operational definition makes measuring constructs in real world possible.

Data consists of samples (rows) and variables (columns).

In order to perform research correctly, make everything constant while measuring 
	one variable. These are called extraneous factors.

Average score of entire population in an experiment: Population Parameter (ùùÅ)
Average score of sample in an experiment: Sample Statistic (xÃÖ)

We can predict population parameter using sample statistics, given a good sample.

ùùÅ - xÃÖ = Sampling Error

Bigger the sample, more the sample statistic will be closer to population parameter.

Another way is to draw multiple random samples which will give interval in which
	population parameter lies.

Plotting samples on a graph:
Variable on x axis is independent variable.
Variable on y axis is dependent variable.

Correlation does not prove causation.

Show correlation => Observational studies surveys
Show causation => Controlled experiment

Controlled experiment uses blinding techniques to avoid biases.
Use random assignment.

--------------------------------------------------------------------------------

Lesson 2: Visualizing Data
--------------------------
Organizing data helps in describing data, seeing pattern, and making decisions.

a. Frequency Table:
Frequency Table is quickist way to organise data into meaningful information.

b. Proportion (Relative Frequency) Table:
How frequency relates to each other.

c. Percentage Table:
Proportion * 100

For any frequency table, the relative frequency should add to 1.

For continuous data, intervals(bins) are used for frequency table.

Histogram: (x axis - Numerical)
Visualizing frequency table of a continuous data.

Bar Graph: (x axis - Categorical)
Visualzing frequency table of a discrete data.

Frequency table results in loss of data.

Symmetrical Histograms are called Normal Distribution.

--------------------------------------------------------------------------------

Lesson 3: Central Tendency
--------------------------
Information representing the data:
a. Mean
b. Median
c. Mode

Mode: Highest frequency element in the data.
Uniform distribution doesn't have a mode.
A distribution can have more than one mode.

Mode of a sample can be different from the mode of the population, hence it can't
	be used to learn about population parameter.

Mean (xÃÖ):
xÃÖ = Œ£ x / n (Sample Mean)
ùùÅ = Œ£ x / N (Population Mean)

The mean of a sample can be used to make inferences about the population it came
	from.

Mean can be misleading in presence of outliers.

Median: 
Middle element after sorting the data.
Median handles outlier nicely. It also exposes them. Hence, they are very robust.

--------------------------------------------------------------------------------

Lesson 4: Variability
---------------------
Range as a way of describing variability of the data.
Range of a distribution quantify the spreadness of the distribution.
Range = max(sample) - min(sample)

Outlier affects the range of the data.

Quartile: Cutting first 25% and last 25% of data (min, 25%, 50%, 75%, max)
Q1 Q2 Q3, where Q2 is median

In order to handle outliers, define 
	Interquartile Range (IQR) = Q3 - Q1

Outlier:
Q1 - 1.5(IQR) < Outlier < Q3 + 1.5(IQR)

Visualization of Quartile and Outlier:
Boxplot

Range or IQR doesn't describe variability properly of different distribution
	differently.

Average Deviation = Œ£ (xi - xÃÖ) / n
Average Absolute Deviation = Œ£ (| xi - xÃÖ |) / n
Average Square Deviation(Variance) = Œ£ (xi - xÃÖ)^2 / n
Standard Deviation = sqrt(Variance)

Problem with average deviation is that it can turn out to be zero.

What's so great about SD anyway?
In normal distribution, where mean = mode = median
68% of data falls under 1 SD of mean.
95% of data falls under 2 SD of mean.

SD of sample < SD of population, since sample (Normal Distribution) comes from 
	68% of the data which has low SD.

In order to handle this, we use Bessel's Correction, i.e divide by (n-1) instead
	of n.

SD of sample: sqrt (Œ£ (xi - xÃÖ)^2 / n)
SD of population using sample: sqrt(Œ£ (xi - xÃÖ)^2 / (n-1))
